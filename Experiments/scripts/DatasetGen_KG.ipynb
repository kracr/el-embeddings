{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generates dataset (entities and relation dictionaries; train, test, validation files) in n-triples format for training KGE models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['GALEN']\n",
    "FILE_PATH = 'data\\{}\\{}_norm_mod.owl'\n",
    "ENTITY_PATH = 'data\\{}\\proscutes\\entities.dict'\n",
    "RELATION_PATH = \"data\\{}\\proscutes\\\\relations.dict\"\n",
    "SAVE_PATH = 'data\\{}\\proscutes\\{}.txt'\n",
    "DATA_PATH = 'data\\{}\\{}_{}.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntityRelations(filename, all_subcls):\n",
    "    classes = {}\n",
    "    relations = {}\n",
    "    triples = {}\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            # Ignore SubObjectPropertyOf\n",
    "            if line.startswith('SubObjectPropertyOf'):\n",
    "                line = line.strip()[20:-1]\n",
    "                if line.startswith('ObjectPropertyChain'):\n",
    "                    line_chain = line.strip()[20:-1]\n",
    "                    line1 = line.split(\")\")\n",
    "                    line10 = line1[0].split()\n",
    "                    r1 = line10[0].strip()\n",
    "                    r2 = line10[1].strip()\n",
    "                    r3 = line1[1].strip()\n",
    "                    if r1 not in relations:\n",
    "                        relations[r1] = len(relations)\n",
    "                    if r2 not in relations:\n",
    "                        relations[r2] = len(relations)\n",
    "                    if r3 not in relations:\n",
    "                        relations[r3] = len(relations)\n",
    "                else:\n",
    "                    it = line.split(' ')\n",
    "                    r1 = it[0].strip()\n",
    "                    r2 = it[1].strip()\n",
    "                    if r1 not in relations:\n",
    "                        relations[r1] = len(relations)\n",
    "                    if r2 not in relations:\n",
    "                        relations[r2] = len(relations)\n",
    "            # Ignore SubClassOf()\n",
    "            line = line.strip()[11:-1]\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith('ObjectIntersectionOf('):\n",
    "                # C and D SubClassOf E\n",
    "                # triple????\n",
    "                it = line.split(' ')\n",
    "                c = it[0][21:]\n",
    "                d = it[1][:-1]\n",
    "                e = it[2]\n",
    "                if c not in classes:\n",
    "                    classes[c] = len(classes)\n",
    "                if d not in classes:\n",
    "                    classes[d] = len(classes)\n",
    "                if e not in classes:\n",
    "                    classes[e] = len(classes)\n",
    "                form = 'nf2'\n",
    "                if e == 'owl:Nothing':\n",
    "                    form = 'disjoint'\n",
    "            elif line.startswith('ObjectSomeValuesFrom('):\n",
    "                # R some C SubClassOf D\n",
    "                # (d, r, c)\n",
    "                it = line.split(' ')\n",
    "                r = it[0][21:].strip()\n",
    "                c = it[1][:-1]\n",
    "                d = it[2]\n",
    "                if c not in classes:\n",
    "                    classes[c] = len(classes)\n",
    "                if d not in classes:\n",
    "                    classes[d] = len(classes)\n",
    "                if r not in relations:\n",
    "                    relations[r] = len(relations)\n",
    "                if d not in triples:\n",
    "                    triples[d] = {}\n",
    "                if c not in triples[d]:\n",
    "                    triples[d][c] = []\n",
    "                triples[d][c].append(r)\n",
    "            elif line.find('ObjectSomeValuesFrom') != -1:\n",
    "                # C SubClassOf R some D\n",
    "                # (c, r, d)\n",
    "                it = line.split(' ')\n",
    "                c = it[0]\n",
    "                r = it[1][21:].strip()\n",
    "                d = it[2][:-1]\n",
    "                if c not in classes:\n",
    "                    classes[c] = len(classes)\n",
    "                if d not in classes:\n",
    "                    classes[d] = len(classes)\n",
    "                if r not in relations:\n",
    "                    relations[r] = len(relations)\n",
    "                if c not in triples:\n",
    "                    triples[c] = {}\n",
    "                if d not in triples[c]:\n",
    "                    triples[c][d] = []\n",
    "                triples[c][d].append(r)\n",
    "            else:\n",
    "                # C SubClassOf D\n",
    "                # (c, subclass, d)\n",
    "                it = line.split(' ')\n",
    "                c = it[0]\n",
    "                d = it[1]\n",
    "                r = 'SubClassOf'\n",
    "                if r not in relations:\n",
    "                    relations[r] = len(relations)\n",
    "                if c not in classes:\n",
    "                    classes[c] = len(classes)\n",
    "                if d not in classes:\n",
    "                    classes[d] = len(classes)\n",
    "                if c not in triples:\n",
    "                    triples[c] = {}\n",
    "                if d not in triples[c]:\n",
    "                    triples[c][d] = []\n",
    "                triples[c][d].append(r)\n",
    "    if 'owl:Thing' not in classes:\n",
    "        classes['owl:Thing'] = len(classes)\n",
    "    prot_ids = []\n",
    "    class_keys = list(classes.keys())\n",
    "    for val in all_subcls:\n",
    "        if val not in class_keys:\n",
    "            cid = len(classes)\n",
    "            classes[val] = cid\n",
    "            prot_ids.append(cid)\n",
    "        else:\n",
    "            prot_ids.append(classes[val])\n",
    "    return classes, relations, triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cls(data_file):\n",
    "    subs=list()\n",
    "    counter=0\n",
    "    with open(data_file,'r') as f:\n",
    "        for line in f:\n",
    "            counter+=1\n",
    "            it = line.strip().split()\n",
    "            cls1 = it[0]\n",
    "            cls2 = it[1]\n",
    "            subs.append(cls1)\n",
    "            subs.append(cls2)\n",
    "    train_cls = list(set(subs))\n",
    "    return train_cls,counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTriples(path, triples):\n",
    "  tuples = []\n",
    "  with open(path) as f:\n",
    "    for line in f:\n",
    "      it = line.strip().split()\n",
    "      cls1 = it[0]\n",
    "      cls2 = it[1]\n",
    "      if cls1 in triples:\n",
    "        if cls2 in triples[cls1]:\n",
    "          for r in triples[cls1][cls2]:\n",
    "            tuples.append(cls1 + '\\t' + r + '\\t' + cls2)\n",
    "        else:\n",
    "          print(line)\n",
    "      else:\n",
    "        print(line)\n",
    "  return tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASETS:\n",
    "  print(\"DATASET \", dataset)\n",
    "  file_path = FILE_PATH.format(dataset, dataset)\n",
    "  train_cls,_ = load_cls(DATA_PATH.format(dataset, dataset, \"train\"))\n",
    "  valid_cls,_ = load_cls(DATA_PATH.format(dataset, dataset, \"valid\"))\n",
    "  classes, relations, triples = getEntityRelations(file_path, train_cls+valid_cls)\n",
    "  for type in [\"train\", \"valid\", \"test\"]:\n",
    "    tups = getTriples(DATA_PATH.format(dataset, dataset, type), triples)\n",
    "    with open(SAVE_PATH.format(dataset, type), 'w') as f:\n",
    "      f.write('\\n'.join(tups))\n",
    "  with open(ENTITY_PATH.format(dataset), 'w') as f:\n",
    "    for class_, id in classes.items():\n",
    "      f.write(str(id) + '\\t' + class_ + '\\n')\n",
    "  with open(RELATION_PATH.format(dataset), 'w') as f:\n",
    "    for relation_, id in relations.items():\n",
    "      f.write(str(id) + '\\t' + relation_ + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'w') as f:\n",
    "  f.write('\\n'.join(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation for KGE training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "import rdflib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N1acd16a1f3e0473dbb207cdb5536ad05 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse('data\\KGE_data\\go\\go_turtle.owl', format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247733\n",
      "22\n",
      "50780\n"
     ]
    }
   ],
   "source": [
    "entities = {}\n",
    "relations = {}\n",
    "nt = {}\n",
    "train = []\n",
    "valid = []\n",
    "test = []\n",
    "for s, p, o in g:\n",
    "  # print(1, s)\n",
    "  # print(2, p)\n",
    "  # print(3, o)\n",
    "  # print(s, '\\t', p, '\\t', o)\n",
    "  if type(s) == rdflib.term.Literal or type(o) == rdflib.term.Literal:\n",
    "    continue\n",
    "  if str(s) not in entities:\n",
    "    entities[str(s)] = len(entities)\n",
    "    # print(s)\n",
    "    # break\n",
    "  if str(o) not in entities:\n",
    "    entities[str(o)] = len(entities)\n",
    "  if str(p) not in relations:\n",
    "    relations[str(p)] = len(relations)\n",
    "  if type(o) == rdflib.term.BNode or type(s) == rdflib.term.BNode:\n",
    "    train.append(\n",
    "      str(s) + '\\t' + str(p) +'\\t' + str(o)\n",
    "    )\n",
    "    continue\n",
    "  if s not in nt:\n",
    "    nt[str(s)] = {}\n",
    "  if o not in nt[str(s)]:\n",
    "    nt[str(s)][str(o)] = []\n",
    "  nt[str(s)][str(o)].append(str(p))\n",
    "  # break\n",
    "print(len(entities))\n",
    "print(len(relations))\n",
    "print(len(nt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tups = [\n",
    "  (\n",
    "    \"data\\GO\\GO_train.txt\",\n",
    "    train,\n",
    "    \"data\\GO\\KG\\\\train.txt\",\n",
    "    False\n",
    "  ),\n",
    "  (\n",
    "    \"data\\GO\\GO_test.txt\",\n",
    "    test,\n",
    "    \"data\\GO\\KG\\\\test.txt\",\n",
    "    True\n",
    "  ),\n",
    "  (\n",
    "    \"data\\GO\\GO_valid.txt\",\n",
    "    valid,\n",
    "    \"data\\GO\\KG\\\\valid.txt\",\n",
    "    True\n",
    "  )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\GO\\GO_train.txt 59829\n",
      "data\\GO\\KG\\train.txt 16779 602881\n",
      "data\\GO\\GO_test.txt 8547\n",
      "data\\GO\\KG\\test.txt 2414 2414\n",
      "data\\GO\\GO_valid.txt 17093\n",
      "data\\GO\\KG\\valid.txt 4898 4898\n"
     ]
    }
   ],
   "source": [
    "for path, l, savepath, subclass_only in tups:\n",
    "  with open(path, 'r') as f:\n",
    "    c=0\n",
    "    d=0\n",
    "    for line in f:\n",
    "      c+=1\n",
    "      a, b = line.split()\n",
    "      a = a.strip('<').strip('>')\n",
    "      b = b.strip('<').strip('>')\n",
    "      if a in nt:\n",
    "        if b in nt[a]:\n",
    "          if subclass_only:\n",
    "            r = \"http://www.w3.org/2000/01/rdf-schema#subClassOf\"\n",
    "            if r in nt[a][b]:\n",
    "              l.append(a + '\\t' + r +'\\t' + b)\n",
    "              d+=1\n",
    "            # else:\n",
    "            #   print(nt[a][b], a, b)\n",
    "          else:\n",
    "            for r in nt[a][b]:\n",
    "              l.append(a + '\\t' + r +'\\t' + b)\n",
    "              d+=1\n",
    "  print(path, c)\n",
    "  print(savepath, d, len(l))\n",
    "  with open(savepath, 'w') as f:\n",
    "    f.write(\n",
    "      '\\n'.join(l)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data\\GO\\KG\\\\relations.dict\", 'w') as f:\n",
    "  for k,v in relations.items():\n",
    "    f.write(str(v) + '\\t' + k + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GALEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N55591a507b05470d9dd343e7ecde4125 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse('data\\KGE_data\\galen\\galen_turtle.owl', format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101805\n",
      "10\n",
      "24092\n",
      "data\\GALEN\\GALEN_train.txt 19511\n",
      "data\\GALEN\\KG\\train.txt 4596 211817\n",
      "data\\GALEN\\GALEN_test.txt 2788\n",
      "data\\GALEN\\KG\\test.txt 672 672\n",
      "data\\GALEN\\GALEN_valid.txt 5573\n",
      "data\\GALEN\\KG\\valid.txt 1290 1290\n"
     ]
    }
   ],
   "source": [
    "entities = {}\n",
    "relations = {}\n",
    "nt = {}\n",
    "train = []\n",
    "valid = []\n",
    "test = []\n",
    "for s, p, o in g:\n",
    "  # print(1, s)\n",
    "  # print(2, p)\n",
    "  # print(3, o)\n",
    "  # print(s, '\\t', p, '\\t', o)\n",
    "  if type(s) == rdflib.term.Literal or type(o) == rdflib.term.Literal:\n",
    "    continue\n",
    "  if str(s) not in entities:\n",
    "    entities[str(s)] = len(entities)\n",
    "    # print(s)\n",
    "    # break\n",
    "  if str(o) not in entities:\n",
    "    entities[str(o)] = len(entities)\n",
    "  if str(p) not in relations:\n",
    "    relations[str(p)] = len(relations)\n",
    "  if type(o) == rdflib.term.BNode or type(s) == rdflib.term.BNode:\n",
    "    train.append(\n",
    "      str(s) + '\\t' + str(p) +'\\t' + str(o)\n",
    "    )\n",
    "    continue\n",
    "  if s not in nt:\n",
    "    nt[str(s)] = {}\n",
    "  if o not in nt[str(s)]:\n",
    "    nt[str(s)][str(o)] = []\n",
    "  nt[str(s)][str(o)].append(str(p))\n",
    "  # break\n",
    "print(len(entities))\n",
    "print(len(relations))\n",
    "print(len(nt))\n",
    "tups = [\n",
    "  (\n",
    "    \"data\\GALEN\\GALEN_train.txt\",\n",
    "    train,\n",
    "    \"data\\GALEN\\KG\\\\train.txt\",\n",
    "    False\n",
    "  ),\n",
    "  (\n",
    "    \"data\\GALEN\\GALEN_test.txt\",\n",
    "    test,\n",
    "    \"data\\GALEN\\KG\\\\test.txt\",\n",
    "    True\n",
    "  ),\n",
    "  (\n",
    "    \"data\\GALEN\\GALEN_valid.txt\",\n",
    "    valid,\n",
    "    \"data\\GALEN\\KG\\\\valid.txt\",\n",
    "    True\n",
    "  )\n",
    "]\n",
    "for path, l, savepath, subclass_only in tups:\n",
    "  with open(path, 'r') as f:\n",
    "    c=0\n",
    "    d=0\n",
    "    for line in f:\n",
    "      c+=1\n",
    "      a, b = line.split()\n",
    "      a = a.strip('<').strip('>')\n",
    "      b = b.strip('<').strip('>')\n",
    "      if a in nt:\n",
    "        if b in nt[a]:\n",
    "          if subclass_only:\n",
    "            r = \"http://www.w3.org/2000/01/rdf-schema#subClassOf\"\n",
    "            if r in nt[a][b]:\n",
    "              l.append(a + '\\t' + r +'\\t' + b)\n",
    "              d+=1\n",
    "            # else:\n",
    "            #   print(nt[a][b], a, b)\n",
    "          else:\n",
    "            for r in nt[a][b]:\n",
    "              l.append(a + '\\t' + r +'\\t' + b)\n",
    "              d+=1\n",
    "  print(path, c)\n",
    "  print(savepath, d, len(l))\n",
    "  with open(savepath, 'w') as f:\n",
    "    f.write(\n",
    "      '\\n'.join(l)\n",
    "    )\n",
    "with open(\"data\\GALEN\\KG\\\\entities.dict\", 'w') as f:\n",
    "  for k,v in entities.items():\n",
    "    f.write(str(v) + '\\t' + k + '\\n')\n",
    "with open(\"data\\GALEN\\KG\\\\relations.dict\", 'w') as f:\n",
    "  for k,v in relations.items():\n",
    "    f.write(str(v) + '\\t' + k + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNOMED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nd1da9555b5844119a25fda00555ed360 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Graph()\n",
    "g.parse('data\\KGE_data\\snomed\\snomed_turtle.owl', format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1621878\n",
      "10\n",
      "307756\n",
      "data\\SNOMED\\SNOMED_train.txt 312631\n",
      "data\\SNOMED\\KG\\train.txt 93323 3647565\n",
      "data\\SNOMED\\SNOMED_test.txt 14700\n",
      "data\\SNOMED\\KG\\test.txt 4455 4455\n",
      "data\\SNOMED\\SNOMED_valid.txt 89322\n",
      "data\\SNOMED\\KG\\valid.txt 26410 26410\n"
     ]
    }
   ],
   "source": [
    "entities = {}\n",
    "relations = {}\n",
    "nt = {}\n",
    "train = []\n",
    "valid = []\n",
    "test = []\n",
    "for s, p, o in g:\n",
    "  # print(1, s)\n",
    "  # print(2, p)\n",
    "  # print(3, o)\n",
    "  # print(s, '\\t', p, '\\t', o)\n",
    "  if type(s) == rdflib.term.Literal or type(o) == rdflib.term.Literal:\n",
    "    continue\n",
    "  if str(s) not in entities:\n",
    "    entities[str(s)] = len(entities)\n",
    "    # print(s)\n",
    "    # break\n",
    "  if str(o) not in entities:\n",
    "    entities[str(o)] = len(entities)\n",
    "  if str(p) not in relations:\n",
    "    relations[str(p)] = len(relations)\n",
    "  if type(o) == rdflib.term.BNode or type(s) == rdflib.term.BNode:\n",
    "    train.append(\n",
    "      str(s) + '\\t' + str(p) +'\\t' + str(o)\n",
    "    )\n",
    "    continue\n",
    "  if s not in nt:\n",
    "    nt[str(s)] = {}\n",
    "  if o not in nt[str(s)]:\n",
    "    nt[str(s)][str(o)] = []\n",
    "  nt[str(s)][str(o)].append(str(p))\n",
    "  # break\n",
    "print(len(entities))\n",
    "print(len(relations))\n",
    "print(len(nt))\n",
    "tups = [\n",
    "  (\n",
    "    \"data\\SNOMED\\SNOMED_train.txt\",\n",
    "    train,\n",
    "    \"data\\SNOMED\\KG\\\\train.txt\",\n",
    "    False\n",
    "  ),\n",
    "  (\n",
    "    \"data\\SNOMED\\SNOMED_test.txt\",\n",
    "    test,\n",
    "    \"data\\SNOMED\\KG\\\\test.txt\",\n",
    "    True\n",
    "  ),\n",
    "  (\n",
    "    \"data\\SNOMED\\SNOMED_valid.txt\",\n",
    "    valid,\n",
    "    \"data\\SNOMED\\KG\\\\valid.txt\",\n",
    "    True\n",
    "  )\n",
    "]\n",
    "for path, l, savepath, subclass_only in tups:\n",
    "  with open(path, 'r') as f:\n",
    "    c=0\n",
    "    d=0\n",
    "    for line in f:\n",
    "      c+=1\n",
    "      a, b = line.split()\n",
    "      a = a.strip('<').strip('>')\n",
    "      b = b.strip('<').strip('>')\n",
    "      if a in nt:\n",
    "        if b in nt[a]:\n",
    "          if subclass_only:\n",
    "            r = \"http://www.w3.org/2000/01/rdf-schema#subClassOf\"\n",
    "            if r in nt[a][b]:\n",
    "              l.append(a + '\\t' + r +'\\t' + b)\n",
    "              d+=1\n",
    "            # else:\n",
    "            #   print(nt[a][b], a, b)\n",
    "          else:\n",
    "            for r in nt[a][b]:\n",
    "              l.append(a + '\\t' + r +'\\t' + b)\n",
    "              d+=1\n",
    "  print(path, c)\n",
    "  print(savepath, d, len(l))\n",
    "  with open(savepath, 'w') as f:\n",
    "    f.write(\n",
    "      '\\n'.join(l)\n",
    "    )\n",
    "with open(\"data\\SNOMED\\KG\\\\entities.dict\", 'w') as f:\n",
    "  for k,v in entities.items():\n",
    "    f.write(str(v) + '\\t' + k + '\\n')\n",
    "with open(\"data\\SNOMED\\KG\\\\relations.dict\", 'w') as f:\n",
    "  for k,v in relations.items():\n",
    "    f.write(str(v) + '\\t' + k + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5f7809511e25842ffbb3f1ca618e326904b35a1180604f8b17019aadbdccf7f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
