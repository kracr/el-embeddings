{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset for each relation type (for EmEL and variants)\n",
    "* Create 3 variants for each type of relation\n",
    "* Create train, test, validation splits optimally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 3 variants for each type of relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['GALEN', 'GO', 'SNOMED']\n",
    "FILE_PATH = 'data\\{}\\{}_norm_mod.owl'\n",
    "SAVE_PATH = 'data\\{}\\{}_norm_{}.owl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelation(line, ObjectIntersectionOf=False):\n",
    "  if line.startswith('ObjectSomeValuesFrom('):\n",
    "    # R some C SubClassOf D\n",
    "    it = line.split(' ')\n",
    "    r = it[0][21:].strip('\\n')\n",
    "    c = it[1][:-1].strip('\\n')\n",
    "    d = it[2].strip('\\n')\n",
    "    return r, d, c\n",
    "  elif line.find('ObjectSomeValuesFrom') != -1:\n",
    "    # C SubClassOf R some D\n",
    "    it = line.split(' ')\n",
    "    c = it[0].strip('\\n')\n",
    "    r = it[1][21:].strip('\\n')\n",
    "    d = it[2][:-1].strip('\\n')\n",
    "    return r, c, d\n",
    "  elif ObjectIntersectionOf and line.startswith('ObjectIntersectionOf'):\n",
    "    it = line.split(' ')\n",
    "    c = it[0][21:].strip('\\n')\n",
    "    d = it[1][:-1].strip('\\n')\n",
    "    e = it[2].strip('\\n')\n",
    "    return e, c, d\n",
    "  # Ignore SubClassOf and ObjectIntersectionOf\n",
    "  it = line.split(' ')\n",
    "  c = it[0].strip('\\n')\n",
    "  r = 'SubClassOf'\n",
    "  d = it[1][:-1].strip('\\n')\n",
    "  return None, c, d\n",
    "  # return r, c, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelations(file):\n",
    "  relation = {}\n",
    "  with open(file) as f:\n",
    "    for line in f:\n",
    "      if not line:\n",
    "        break\n",
    "      if line.startswith('SubClassOf'):\n",
    "        line = line[11:]\n",
    "        # SubClassOf(ObjectSomeValuesFrom(<http://www.co-ode.org/ontologies/galen#isActedOnSpecificallyBy> <http://www.co-ode.org/ontologies/galen#Haematopinus>) <http://www.co-ode.org/ontologies/galen#NonActiveImplantableDevice>)\n",
    "        # SubClassOf(<http://www.co-ode.org/ontologies/galen#Anonymous-457> ObjectSomeValuesFrom(<http://www.co-ode.org/ontologies/galen#isSpecificSurfaceDivisionOf> <http://www.co-ode.org/ontologies/galen#CervicalRegionOfBack>))\n",
    "        r, c1, c2 = getRelation(line)\n",
    "        if r:\n",
    "          if r not in relation:\n",
    "            relation[r] = []\n",
    "          relation[r].append((c1, c2))\n",
    "  return relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRelationsByType(relations):\n",
    "  relations_by_type = {\n",
    "    '1_1': [],\n",
    "    '1_n': [],\n",
    "    'n_n': []\n",
    "  }\n",
    "  for relation, tups in relations.items():\n",
    "    left = Counter([tup[0] for tup in tups])\n",
    "    right = Counter([tup[1] for tup in tups])\n",
    "    if left.most_common(1)[0][1] == 1 and right.most_common(1)[0][1] == 1:\n",
    "      relations_by_type['1_1'].append(relation)\n",
    "    elif right.most_common(1)[0][1] == 1:\n",
    "      relations_by_type['1_n'].append(relation)\n",
    "    else:\n",
    "      relations_by_type['n_n'].append(relation)\n",
    "  return relations_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeAxioms(dataset, file_path, save_path, relations_by_type):\n",
    "  file = {}\n",
    "  count = {}\n",
    "  for k in relations_by_type.keys():\n",
    "    file[k] = open(save_path.format(dataset, dataset, k), 'w')\n",
    "    count[k] = 0\n",
    "    print(\"Writing to\", file[k])\n",
    "  count['other'] = 0\n",
    "  with open(file_path) as f:\n",
    "    for line in f:\n",
    "      if line.startswith('EquivalentClasses'):\n",
    "        continue\n",
    "      if line.startswith('SubClassOf'):\n",
    "        s_line = line[11:]\n",
    "        if not s_line:\n",
    "          break\n",
    "        # SubClassOf(ObjectSomeValuesFrom(<http://www.co-ode.org/ontologies/galen#isActedOnSpecificallyBy> <http://www.co-ode.org/ontologies/galen#Haematopinus>) <http://www.co-ode.org/ontologies/galen#NonActiveImplantableDevice>)\n",
    "        # SubClassOf(<http://www.co-ode.org/ontologies/galen#Anonymous-457> ObjectSomeValuesFrom(<http://www.co-ode.org/ontologies/galen#isSpecificSurfaceDivisionOf> <http://www.co-ode.org/ontologies/galen#CervicalRegionOfBack>))\n",
    "        r, c1, c2 = getRelation(s_line)\n",
    "        if r:\n",
    "          if r in relations_by_type['1_1']:\n",
    "            file['1_1'].write(line)\n",
    "            count['1_1']+=1\n",
    "          elif r in relations_by_type['1_n']:\n",
    "            file['1_n'].write(line)\n",
    "            count['1_n']+=1\n",
    "          else:\n",
    "            file['n_n'].write(line)\n",
    "            count['n_n']+=1\n",
    "        else:\n",
    "          # Write SubClassOf axioms to all files\n",
    "          for k in relations_by_type.keys():\n",
    "            file[k].write(line)\n",
    "          count['other']+=1\n",
    "      else:\n",
    "        for k in relations_by_type.keys():\n",
    "          file[k].write(line)\n",
    "        count['other']+=1\n",
    "  for k,v in file.items():\n",
    "    v.close()\n",
    "  for k,v in count.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GALEN\n",
      "396\n",
      "1_1 180 2199\n",
      "1_n 17 1331\n",
      "n_n 199 38185\n",
      "GO\n",
      "8\n",
      "1_1 1 1\n",
      "1_n 0 0\n",
      "n_n 7 32452\n",
      "SNOMED\n",
      "57\n",
      "1_1 0 0\n",
      "1_n 1 200641\n",
      "n_n 56 314138\n"
     ]
    }
   ],
   "source": [
    "for dataset in DATASETS:\n",
    "  print(dataset)\n",
    "  file_path = FILE_PATH.format(dataset, dataset)\n",
    "  relations = getRelations(file_path)\n",
    "  print(len(relations))\n",
    "  relations_by_type = getRelationsByType(relations)\n",
    "  for k, v in relations_by_type.items():\n",
    "    # print(v)\n",
    "    naxioms = sum([len(relations[vv]) for vv in v])\n",
    "    print(k, len(v), naxioms)\n",
    "    with open(\"data/\"+dataset+\"/\"+k+\"/\"+dataset+\"_\"+k+\"_relations.txt\", 'w') as f:\n",
    "      f.write(\n",
    "        '\\n'.join(v)\n",
    "      )\n",
    "  # writeAxioms(dataset, file_path, SAVE_PATH, relations_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = ['OWL2EL_5']\n",
    "FILE_PATH = 'data/{}/normalized.owl'\n",
    "SAVE_PATH = 'data/{}/{}_norm_{}.owl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OWL2EL_5\n",
      "60\n",
      "['<http://benchmark/OWL2Bench#hasResearchProject>', '<http://benchmark/OWL2Bench#isTaughtBy>', '<http://benchmark/OWL2Bench#isHeadOf>', '<http://benchmark/OWL2Bench#hasDean>', '<http://benchmark/OWL2Bench#hasWork>', '<http://benchmark/OWL2Bench#worksFor>', '<http://benchmark/OWL2Bench#publicationResearch>', '<http://benchmark/OWL2Bench#isStudentOf>', '<http://benchmark/OWL2Bench#isResearchGroupOf>', '<http://benchmark/OWL2Bench#hasPhDProgram>', '<http://benchmark/OWL2Bench#hasUGProgram>', '<http://benchmark/OWL2Bench#isDepartmentOf>', '<http://benchmark/OWL2Bench#hasPGProgram>', '<http://benchmark/OWL2Bench#isDeanOf>', '<http://benchmark/OWL2Bench#isMemberOf>', '<http://benchmark/OWL2Bench#hasAdvisor>', '<http://benchmark/OWL2Bench#advises>', '<http://benchmark/OWL2Bench#isAdvisorOf>', '<http://benchmark/OWL2Bench#hasDegreeFrom>', '<http://benchmark/OWL2Bench#tenured>', '<http://benchmark/OWL2Bench#isFacultyOf>', '<http://benchmark/OWL2Bench#isCollegeOf>', '<http://benchmark/OWL2Bench#hasSubOrganization>', '<http://benchmark/OWL2Bench#hasMember>', '<http://benchmark/OWL2Bench#orgPublication>', '<http://benchmark/OWL2Bench#hasPart>']\n",
      "1_1 26 5721\n",
      "['<http://benchmark/OWL2Bench#offerCourse>', '<http://benchmark/OWL2Bench#hasResearchAssistant>', '<http://benchmark/OWL2Bench#hasProgram>', '<http://benchmark/OWL2Bench#hasResearchGroup>']\n",
      "1_n 4 5963\n",
      "['<http://benchmark/OWL2Bench#teachesCourse>', '<http://benchmark/OWL2Bench#likes>', '<http://benchmark/OWL2Bench#dislikes>', '<http://benchmark/OWL2Bench#knows>', '<http://benchmark/OWL2Bench#isCrazyAbout>', '<http://benchmark/OWL2Bench#loves>', '<http://benchmark/OWL2Bench#enrollFor>', '<http://benchmark/OWL2Bench#takesCourse>', '<http://benchmark/OWL2Bench#hasAuthor>', '<http://benchmark/OWL2Bench#isAssistantProfessorOf>', '<http://benchmark/OWL2Bench#isFullProfessorOf>', '<http://benchmark/OWL2Bench#isAdvisedBy>', '<http://benchmark/OWL2Bench#hasSameHomeTownWith>', '<http://benchmark/OWL2Bench#enrollIn>', '<http://benchmark/OWL2Bench#isAssociateProfessorOf>', '<http://benchmark/OWL2Bench#isSystemStaffOf>', '<http://benchmark/OWL2Bench#hasCollaborationWith>', '<http://benchmark/OWL2Bench#isOtherStaffOf>', '<http://benchmark/OWL2Bench#isLecturerOf>', '<http://benchmark/OWL2Bench#isPostDocOf>', '<http://benchmark/OWL2Bench#isVisitingProfessorOf>', '<http://benchmark/OWL2Bench#isPartOf>', '<http://benchmark/OWL2Bench#isTeachingAssistantOf>', '<http://benchmark/OWL2Bench#hasMajor>', '<http://benchmark/OWL2Bench#isClericalStaffOf>', '<http://benchmark/OWL2Bench#hasMasterDegreeFrom>', '<http://benchmark/OWL2Bench#hasDoctoralDegreeFrom>', '<http://benchmark/OWL2Bench#hasUndergraduateDegreeFrom>', '<http://benchmark/OWL2Bench#isAffiliatedOrganizationOf>', '<http://benchmark/OWL2Bench#hasCollegeDiscipline>']\n",
      "n_n 30 168967\n"
     ]
    }
   ],
   "source": [
    "for dataset in DATASETS[1:]:\n",
    "  print(dataset)\n",
    "  file_path = FILE_PATH.format(dataset)\n",
    "  relations = getRelations(file_path)\n",
    "  print(len(relations))\n",
    "  relations_by_type = getRelationsByType(relations)\n",
    "  for k, v in relations_by_type.items():\n",
    "    print(v)\n",
    "    with open(\"data/OWL2EL_5/OWL2EL_5_{}_relations.txt\".format(k), \"w\") as f:\n",
    "      f.write(\"\\n\".join(v))\n",
    "    naxioms = sum([len(relations[vv]) for vv in v])\n",
    "    print(k, len(v), naxioms)\n",
    "  writeAxioms(dataset, file_path, SAVE_PATH, relations_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test, Validation splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"SNOMED\"\n",
    "DATASET_SPLIT = [\n",
    "  \"1_1\", \"1_n\", \n",
    "  \"n_n\"]\n",
    "FILE_PATH = \"data/{}/{}_norm_{}.owl\"\n",
    "SAVE_PATH = \"data/{}/{}/{}.{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1\n",
      "total 474407\n",
      "Expected train, valid, test: 332084 94881 47442\n",
      "Added to train from other axioms 27001 27001\n",
      "474407 446616 790\n",
      "Classes not added 250120 250120\n",
      "474407 217755 790\n",
      "Added to train from subclass axioms 228861\n",
      "remaining subclass axioms and other axioms 217755 790\n",
      "train, valid, test 76222 94881 47442\n",
      "Train, valid, test left 76222 94881 47442\n",
      "added to train from other axioms 790\n",
      "added to train from subclass axioms 75432\n",
      "Total: 474407\n",
      "left 0 0\n",
      "0 0 0\n",
      "1_n\n",
      "total 675048\n",
      "Expected train, valid, test: 472533 135009 67506\n",
      "Added to train from other axioms 186673 186673\n",
      "675048 446616 41759\n",
      "Classes not added 33831 33831\n",
      "675048 413018 41759\n",
      "Added to train from subclass axioms 33598\n",
      "remaining subclass axioms and other axioms 413018 41759\n",
      "train, valid, test 252262 135009 67506\n",
      "Train, valid, test left 252262 135009 67506\n",
      "added to train from other axioms 41759\n",
      "added to train from subclass axioms 210503\n",
      "Total: 675048\n",
      "left 0 0\n",
      "0 0 0\n",
      "n_n\n",
      "total 788545\n",
      "Expected train, valid, test: 551981 157709 78855\n",
      "Added to train from other axioms 212932 212932\n",
      "788545 446616 128997\n",
      "Classes not added 66101 66101\n",
      "788545 381121 128997\n",
      "Added to train from subclass axioms 65495\n",
      "remaining subclass axioms and other axioms 381121 128997\n",
      "train, valid, test 273554 157709 78855\n",
      "Train, valid, test left 273554 157709 78855\n",
      "added to train from other axioms 128997\n",
      "added to train from subclass axioms 144557\n",
      "Total: 788545\n",
      "left 0 0\n",
      "0 0 0\n"
     ]
    }
   ],
   "source": [
    "for SPLIT in DATASET_SPLIT:\n",
    "  file_path = FILE_PATH.format(DATASET, DATASET, SPLIT)\n",
    "  print(SPLIT)\n",
    "  file = {}\n",
    "  # count = {}\n",
    "  for k in ['train', 'valid', 'test']:\n",
    "    file[k] = open(SAVE_PATH.format(DATASET, SPLIT, k, \"txt\"), 'w')\n",
    "    # count[k] = 0\n",
    "  file['train_norm'] = open(SAVE_PATH.format(DATASET, SPLIT, \"train_norm\", \"owl\"), 'w')\n",
    "  # count['train_norm'] = 0\n",
    "  subclass_axioms = []\n",
    "  other_axioms = []\n",
    "  co=0\n",
    "  train = 0\n",
    "  valid = 0\n",
    "  test = 0\n",
    "  classes = {}\n",
    "  relations = {}\n",
    "  subclass_classes = {}\n",
    "  # First pass: Get all classes in subclass axioms, number of axioms\n",
    "  with open(file_path) as f:\n",
    "    for line in f:\n",
    "      co+=1\n",
    "      og_line = line\n",
    "      if line.startswith(\"SubClassOf\"):\n",
    "        line = line.strip()[11:-1]\n",
    "        if not line:\n",
    "          co-=1\n",
    "          continue\n",
    "        if not line.startswith(\"ObjectIntersectionOf(\") and not line.startswith(\"ObjectSomeValuesFrom(\") and line.find(\"ObjectSomeValuesFrom(\") == -1:\n",
    "          # SubClassOf C D\n",
    "          it = line.split(' ')\n",
    "          c = it[0]\n",
    "          d = it[1]\n",
    "          # subclass_axioms.append((og_line, c, d))\n",
    "          if c not in subclass_classes:\n",
    "            subclass_classes[c] = len(subclass_classes)\n",
    "          if d not in subclass_classes:\n",
    "            subclass_classes[d] = len(subclass_classes)\n",
    "\n",
    "  train = int(co*0.7)\n",
    "  valid = int(co*0.2)\n",
    "  test = co - train- valid\n",
    "  ex_train = train\n",
    "  total_train = train\n",
    "  count=0\n",
    "  print(\"total\", co)\n",
    "  print(\"Expected train, valid, test:\", train, valid, test)\n",
    "\n",
    "  # Second pass: add all relation (rbox) axioms and only add non subclass axioms containing classes in subclass axioms\n",
    "  with open(file_path) as f:\n",
    "    for line in f:\n",
    "      og_line = line\n",
    "      if line.startswith('SubObjectPropertyOf'):\n",
    "        line = line.strip()[20:-1]\n",
    "        if line.startswith('ObjectPropertyChain'):\n",
    "          line_chain = line.strip()[20:-1]\n",
    "          line1 = line.split(\")\")\n",
    "          line10 = line1[0].split()\n",
    "          if len(line10) < 2:\n",
    "            continue\n",
    "          r1 = line10[0]\n",
    "          r2 = line10[1]\n",
    "          r3 = line1[1]\n",
    "          # if train and (r1 not in relations or r2 not in relations or r3 not in relations):\n",
    "          file['train_norm'].write(og_line)\n",
    "          file['train'].write(r1 + ' ' + r2 + '\\n')\n",
    "          count+=1\n",
    "          train-=1\n",
    "            # if r1 not in relations:\n",
    "            #   relations[r1] = len(relations)\n",
    "            # if r2 not in relations:\n",
    "            #   relations[r2] = len(relations)\n",
    "            # if r3 not in relations:\n",
    "            #   relations[r3] = len(relations)\n",
    "          # else:\n",
    "            # other_axioms.append((og_line, r1, r2, r3))\n",
    "        else:\n",
    "          # print(\"Inside sub obj prop\")\n",
    "          it = line.split(' ')\n",
    "          r1 = it[0]\n",
    "          r2 = it[1]\n",
    "          file['train_norm'].write(og_line)\n",
    "          file['train'].write(r1 + ' ' + r2 + '\\n')\n",
    "          count+=1\n",
    "          train-=1\n",
    "          # other_axioms.append((og_line, r1, r2, \"\"))\n",
    "        continue\n",
    "      line = line.strip()[11:-1]\n",
    "#           print(line)\n",
    "      if not line:\n",
    "        print(og_line)\n",
    "        continue\n",
    "      if line.startswith('ObjectIntersectionOf('):\n",
    "        # C and D SubClassOf E\n",
    "        it = line.split(' ')\n",
    "        c = it[0][21:]\n",
    "        d = it[1][:-1]\n",
    "        e = it[2]\n",
    "        if train and (c in subclass_classes or d in subclass_classes or e in subclass_classes):\n",
    "          file['train_norm'].write(og_line)\n",
    "          file['train'].write(c + ' ' + d + '\\n')\n",
    "          count+=1\n",
    "          train-=1\n",
    "          if c in subclass_classes:\n",
    "            subclass_classes.pop(c)\n",
    "          if d in subclass_classes:\n",
    "            subclass_classes.pop(d)\n",
    "          if e in subclass_classes:\n",
    "            subclass_classes.pop(e)\n",
    "          if c not in classes:\n",
    "            classes[c] = len(classes)\n",
    "          if d not in classes:\n",
    "            classes[d] = len(classes)\n",
    "          if e not in classes:\n",
    "            classes[e] = len(classes)\n",
    "        else:\n",
    "          other_axioms.append((og_line, c, d, e))\n",
    "      elif line.startswith('ObjectSomeValuesFrom('):\n",
    "        # R some C SubClassOf D\n",
    "        it = line.split(' ')\n",
    "        r = it[0][21:]\n",
    "        c = it[1][:-1]\n",
    "        d = it[2]\n",
    "        if train and (c in subclass_classes or d in subclass_classes or r not in relations):\n",
    "          file['train_norm'].write(og_line)\n",
    "          file['train'].write(c + ' ' + d + '\\n')\n",
    "          count+=1\n",
    "          train-=1\n",
    "          if c in subclass_classes:\n",
    "            subclass_classes.pop(c)\n",
    "          if d in subclass_classes:\n",
    "            subclass_classes.pop(d)\n",
    "          if c not in classes:\n",
    "            classes[c] = len(classes)\n",
    "          if d not in classes:\n",
    "            classes[d] = len(classes)\n",
    "          if r not in relations:\n",
    "            relations[r] = len(relations)\n",
    "        else:\n",
    "          other_axioms.append((og_line, r, c, d))\n",
    "      elif line.find('ObjectSomeValuesFrom') != -1:\n",
    "        # C SubClassOf R some D\n",
    "        it = line.split(' ')\n",
    "        c = it[0]\n",
    "        r = it[1][21:]\n",
    "        d = it[2][:-1]\n",
    "        if train and (c in subclass_classes or d in subclass_classes or r not in relations):\n",
    "          file['train_norm'].write(og_line)\n",
    "          file['train'].write(c + ' ' + d + '\\n')\n",
    "          count+=1\n",
    "          train-=1\n",
    "          if c in subclass_classes:\n",
    "            subclass_classes.pop(c)\n",
    "          if d in subclass_classes:\n",
    "            subclass_classes.pop(d)\n",
    "          if c not in classes:\n",
    "            classes[c] = len(classes)\n",
    "          if d not in classes:\n",
    "            classes[d] = len(classes)\n",
    "          if r not in relations:\n",
    "            relations[r] = len(relations)\n",
    "        else:\n",
    "          other_axioms.append((og_line, r, c, d))\n",
    "      else:\n",
    "        # C SubClassOf D\n",
    "        it = line.split(' ')\n",
    "        c = it[0]\n",
    "        d = it[1]\n",
    "        subclass_axioms.append((og_line, c, d))\n",
    "  print(\"Added to train from other axioms\", ex_train-train, count)\n",
    "  print(count+len(subclass_axioms)+len(other_axioms), len(subclass_axioms), len(other_axioms))\n",
    "  print(\"Classes not added\", len([k for k in subclass_classes if k not in classes]), len(subclass_classes))\n",
    "  ex_train = train\n",
    "  # Second pass\n",
    "  temp = []\n",
    "  for tup in subclass_axioms:\n",
    "    line, c, d = tup\n",
    "    if train and (c in subclass_classes or d in subclass_classes):\n",
    "#       print(line)\n",
    "      file['train_norm'].write(line)\n",
    "      file['train'].write(c + ' ' + d + '\\n')\n",
    "      count+=1\n",
    "      train-=1\n",
    "      if c in subclass_classes:\n",
    "        subclass_classes.pop(c)\n",
    "      if d in subclass_classes:\n",
    "        subclass_classes.pop(d)\n",
    "      if c not in classes:\n",
    "        classes[c] = len(classes)\n",
    "      if d not in classes:\n",
    "        classes[d] = len(classes)\n",
    "    else:\n",
    "      temp.append((line, c, d))\n",
    "  subclass_axioms = temp\n",
    "  print(count+len(subclass_axioms)+len(other_axioms), len(subclass_axioms), len(other_axioms))\n",
    "  print(\"Added to train from subclass axioms\", ex_train-train)\n",
    "  ex_train = train\n",
    "\n",
    "  print(\"remaining subclass axioms and other axioms\", len(subclass_axioms), len(other_axioms))\n",
    "  print(\"train, valid, test\", train, valid, test)\n",
    "\n",
    "  if len(subclass_axioms) < test+valid:\n",
    "    # recalculate test, validation, training sample counts\n",
    "    c = len(subclass_axioms)\n",
    "    valid = int(c*0.66)\n",
    "    test = c - valid\n",
    "    train = max(0, min(train, int(c*0.7/0.3) - (total_train-train)))\n",
    "  ex_train = train\n",
    "\n",
    "  print(\"Train, valid, test left\", train, valid, test)\n",
    "\n",
    "  temp = []\n",
    "  while test and subclass_axioms != []:\n",
    "    line, c, d = subclass_axioms.pop()\n",
    "    if c not in subclass_classes and d not in subclass_classes:\n",
    "      file['test'].write(c + ' ' + d + '\\n')\n",
    "      test-=1\n",
    "      count+=1\n",
    "    else:\n",
    "      temp.append((line, c, d))\n",
    "  while valid and subclass_axioms != []:\n",
    "    line, c, d =  subclass_axioms.pop()\n",
    "    if c not in subclass_classes and d not in subclass_classes:\n",
    "      file['valid'].write(c + ' ' + d + '\\n')\n",
    "      valid-=1\n",
    "      count+=1\n",
    "    else:\n",
    "      temp.append((line, c, d))\n",
    "  subclass_axioms.extend(temp)\n",
    "  while train and other_axioms != []:\n",
    "    line, r, c, d = other_axioms.pop()\n",
    "#     if c in classes and d in classes:\n",
    "    file['train'].write(c + ' ' + d + '\\n')\n",
    "    file['train_norm'].write(line)\n",
    "    count+=1\n",
    "    train-=1\n",
    "  print(\"added to train from other axioms\", ex_train-train)\n",
    "  ex_train = train\n",
    "  while train and subclass_axioms != []:\n",
    "    line, c, d =  subclass_axioms.pop()\n",
    "#     if c in classes or d in classes:\n",
    "    file['train'].write(c + ' ' + d + '\\n')\n",
    "    file['train_norm'].write(line)\n",
    "    count+=1\n",
    "    train -=1\n",
    "  print(\"added to train from subclass axioms\", ex_train-train)\n",
    "  for k in ['train', 'valid', 'test']:\n",
    "    file[k].close()\n",
    "  print(\"Total:\", count)\n",
    "  print(\"left\", len(subclass_axioms), len(other_axioms))\n",
    "  print(train, test, valid)\n",
    "  # for k in ['train', 'valid', 'test']:\n",
    "  #   with open(SAVE_PATH.format(DATASET, SPLIT, k, \"txt\")) as f:\n",
    "  #     c=0\n",
    "  #     for line in f:\n",
    "  #       c+=1\n",
    "  #     print(\"Final\", k, c)\n",
    "  # print(\"total added to train, valid, test\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4480e32245891b07b354378c7dbc380a1b3f17ee24171af64af582c25470e498"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
